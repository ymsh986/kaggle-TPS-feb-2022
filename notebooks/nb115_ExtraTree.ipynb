{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPS-Feb-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '115'\n",
    "dataset_NB = '002'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import mode\n",
    "import time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier, early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "##### Load train and Test set\n",
    "train = pd.read_pickle(f\"../data/processed/nb{dataset_NB}_train.pkl\", compression='zip')\n",
    "test = pd.read_pickle(f\"../data/processed/nb{dataset_NB}_test.pkl\", compression='zip')\n",
    "\n",
    "submission = pd.read_csv('../data/raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>train_len = len(train)\n",
    "#test_id = test['row_id']\n",
    "\n",
    "#dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n",
    "# reset_index: indexを0から順に振り直す\n",
    "# drop: Falseの場合、元のindexが「index」列が新たに生成されて残る。Trueの場合「index」列は作られない。\n",
    "\n",
    "#dataset = dataset.drop(columns=['row_id'])\n",
    "#train = train.drop(columns=['row_id'])\n",
    "\n",
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A0T0G0C10',\n",
       " 'A0T0G1C9',\n",
       " 'A0T0G2C8',\n",
       " 'A0T0G3C7',\n",
       " 'A0T0G4C6',\n",
       " 'A0T0G5C5',\n",
       " 'A0T0G6C4',\n",
       " 'A0T0G7C3',\n",
       " 'A0T0G8C2',\n",
       " 'A0T0G9C1',\n",
       " 'A0T0G10C0',\n",
       " 'A0T1G0C9',\n",
       " 'A0T1G1C8',\n",
       " 'A0T1G2C7',\n",
       " 'A0T1G3C6',\n",
       " 'A0T1G4C5',\n",
       " 'A0T1G5C4',\n",
       " 'A0T1G6C3',\n",
       " 'A0T1G7C2',\n",
       " 'A0T1G8C1',\n",
       " 'A0T1G9C0',\n",
       " 'A0T2G0C8',\n",
       " 'A0T2G1C7',\n",
       " 'A0T2G2C6',\n",
       " 'A0T2G3C5',\n",
       " 'A0T2G4C4',\n",
       " 'A0T2G5C3',\n",
       " 'A0T2G6C2',\n",
       " 'A0T2G7C1',\n",
       " 'A0T2G8C0',\n",
       " 'A0T3G0C7',\n",
       " 'A0T3G1C6',\n",
       " 'A0T3G2C5',\n",
       " 'A0T3G3C4',\n",
       " 'A0T3G4C3',\n",
       " 'A0T3G5C2',\n",
       " 'A0T3G6C1',\n",
       " 'A0T3G7C0',\n",
       " 'A0T4G0C6',\n",
       " 'A0T4G1C5',\n",
       " 'A0T4G2C4',\n",
       " 'A0T4G3C3',\n",
       " 'A0T4G4C2',\n",
       " 'A0T4G5C1',\n",
       " 'A0T4G6C0',\n",
       " 'A0T5G0C5',\n",
       " 'A0T5G1C4',\n",
       " 'A0T5G2C3',\n",
       " 'A0T5G3C2',\n",
       " 'A0T5G4C1',\n",
       " 'A0T5G5C0',\n",
       " 'A0T6G0C4',\n",
       " 'A0T6G1C3',\n",
       " 'A0T6G2C2',\n",
       " 'A0T6G3C1',\n",
       " 'A0T6G4C0',\n",
       " 'A0T7G0C3',\n",
       " 'A0T7G1C2',\n",
       " 'A0T7G2C1',\n",
       " 'A0T7G3C0',\n",
       " 'A0T8G0C2',\n",
       " 'A0T8G1C1',\n",
       " 'A0T8G2C0',\n",
       " 'A0T9G0C1',\n",
       " 'A0T9G1C0',\n",
       " 'A0T10G0C0',\n",
       " 'A1T0G0C9',\n",
       " 'A1T0G1C8',\n",
       " 'A1T0G2C7',\n",
       " 'A1T0G3C6',\n",
       " 'A1T0G4C5',\n",
       " 'A1T0G5C4',\n",
       " 'A1T0G6C3',\n",
       " 'A1T0G7C2',\n",
       " 'A1T0G8C1',\n",
       " 'A1T0G9C0',\n",
       " 'A1T1G0C8',\n",
       " 'A1T1G1C7',\n",
       " 'A1T1G2C6',\n",
       " 'A1T1G3C5',\n",
       " 'A1T1G4C4',\n",
       " 'A1T1G5C3',\n",
       " 'A1T1G6C2',\n",
       " 'A1T1G7C1',\n",
       " 'A1T1G8C0',\n",
       " 'A1T2G0C7',\n",
       " 'A1T2G1C6',\n",
       " 'A1T2G2C5',\n",
       " 'A1T2G3C4',\n",
       " 'A1T2G4C3',\n",
       " 'A1T2G5C2',\n",
       " 'A1T2G6C1',\n",
       " 'A1T2G7C0',\n",
       " 'A1T3G0C6',\n",
       " 'A1T3G1C5',\n",
       " 'A1T3G2C4',\n",
       " 'A1T3G3C3',\n",
       " 'A1T3G4C2',\n",
       " 'A1T3G5C1',\n",
       " 'A1T3G6C0',\n",
       " 'A1T4G0C5',\n",
       " 'A1T4G1C4',\n",
       " 'A1T4G2C3',\n",
       " 'A1T4G3C2',\n",
       " 'A1T4G4C1',\n",
       " 'A1T4G5C0',\n",
       " 'A1T5G0C4',\n",
       " 'A1T5G1C3',\n",
       " 'A1T5G2C2',\n",
       " 'A1T5G3C1',\n",
       " 'A1T5G4C0',\n",
       " 'A1T6G0C3',\n",
       " 'A1T6G1C2',\n",
       " 'A1T6G2C1',\n",
       " 'A1T6G3C0',\n",
       " 'A1T7G0C2',\n",
       " 'A1T7G1C1',\n",
       " 'A1T7G2C0',\n",
       " 'A1T8G0C1',\n",
       " 'A1T8G1C0',\n",
       " 'A1T9G0C0',\n",
       " 'A2T0G0C8',\n",
       " 'A2T0G1C7',\n",
       " 'A2T0G2C6',\n",
       " 'A2T0G3C5',\n",
       " 'A2T0G4C4',\n",
       " 'A2T0G5C3',\n",
       " 'A2T0G6C2',\n",
       " 'A2T0G7C1',\n",
       " 'A2T0G8C0',\n",
       " 'A2T1G0C7',\n",
       " 'A2T1G1C6',\n",
       " 'A2T1G2C5',\n",
       " 'A2T1G3C4',\n",
       " 'A2T1G4C3',\n",
       " 'A2T1G5C2',\n",
       " 'A2T1G6C1',\n",
       " 'A2T1G7C0',\n",
       " 'A2T2G0C6',\n",
       " 'A2T2G1C5',\n",
       " 'A2T2G2C4',\n",
       " 'A2T2G3C3',\n",
       " 'A2T2G4C2',\n",
       " 'A2T2G5C1',\n",
       " 'A2T2G6C0',\n",
       " 'A2T3G0C5',\n",
       " 'A2T3G1C4',\n",
       " 'A2T3G2C3',\n",
       " 'A2T3G3C2',\n",
       " 'A2T3G4C1',\n",
       " 'A2T3G5C0',\n",
       " 'A2T4G0C4',\n",
       " 'A2T4G1C3',\n",
       " 'A2T4G2C2',\n",
       " 'A2T4G3C1',\n",
       " 'A2T4G4C0',\n",
       " 'A2T5G0C3',\n",
       " 'A2T5G1C2',\n",
       " 'A2T5G2C1',\n",
       " 'A2T5G3C0',\n",
       " 'A2T6G0C2',\n",
       " 'A2T6G1C1',\n",
       " 'A2T6G2C0',\n",
       " 'A2T7G0C1',\n",
       " 'A2T7G1C0',\n",
       " 'A2T8G0C0',\n",
       " 'A3T0G0C7',\n",
       " 'A3T0G1C6',\n",
       " 'A3T0G2C5',\n",
       " 'A3T0G3C4',\n",
       " 'A3T0G4C3',\n",
       " 'A3T0G5C2',\n",
       " 'A3T0G6C1',\n",
       " 'A3T0G7C0',\n",
       " 'A3T1G0C6',\n",
       " 'A3T1G1C5',\n",
       " 'A3T1G2C4',\n",
       " 'A3T1G3C3',\n",
       " 'A3T1G4C2',\n",
       " 'A3T1G5C1',\n",
       " 'A3T1G6C0',\n",
       " 'A3T2G0C5',\n",
       " 'A3T2G1C4',\n",
       " 'A3T2G2C3',\n",
       " 'A3T2G3C2',\n",
       " 'A3T2G4C1',\n",
       " 'A3T2G5C0',\n",
       " 'A3T3G0C4',\n",
       " 'A3T3G1C3',\n",
       " 'A3T3G2C2',\n",
       " 'A3T3G3C1',\n",
       " 'A3T3G4C0',\n",
       " 'A3T4G0C3',\n",
       " 'A3T4G1C2',\n",
       " 'A3T4G2C1',\n",
       " 'A3T4G3C0',\n",
       " 'A3T5G0C2',\n",
       " 'A3T5G1C1',\n",
       " 'A3T5G2C0',\n",
       " 'A3T6G0C1',\n",
       " 'A3T6G1C0',\n",
       " 'A3T7G0C0',\n",
       " 'A4T0G0C6',\n",
       " 'A4T0G1C5',\n",
       " 'A4T0G2C4',\n",
       " 'A4T0G3C3',\n",
       " 'A4T0G4C2',\n",
       " 'A4T0G5C1',\n",
       " 'A4T0G6C0',\n",
       " 'A4T1G0C5',\n",
       " 'A4T1G1C4',\n",
       " 'A4T1G2C3',\n",
       " 'A4T1G3C2',\n",
       " 'A4T1G4C1',\n",
       " 'A4T1G5C0',\n",
       " 'A4T2G0C4',\n",
       " 'A4T2G1C3',\n",
       " 'A4T2G2C2',\n",
       " 'A4T2G3C1',\n",
       " 'A4T2G4C0',\n",
       " 'A4T3G0C3',\n",
       " 'A4T3G1C2',\n",
       " 'A4T3G2C1',\n",
       " 'A4T3G3C0',\n",
       " 'A4T4G0C2',\n",
       " 'A4T4G1C1',\n",
       " 'A4T4G2C0',\n",
       " 'A4T5G0C1',\n",
       " 'A4T5G1C0',\n",
       " 'A4T6G0C0',\n",
       " 'A5T0G0C5',\n",
       " 'A5T0G1C4',\n",
       " 'A5T0G2C3',\n",
       " 'A5T0G3C2',\n",
       " 'A5T0G4C1',\n",
       " 'A5T0G5C0',\n",
       " 'A5T1G0C4',\n",
       " 'A5T1G1C3',\n",
       " 'A5T1G2C2',\n",
       " 'A5T1G3C1',\n",
       " 'A5T1G4C0',\n",
       " 'A5T2G0C3',\n",
       " 'A5T2G1C2',\n",
       " 'A5T2G2C1',\n",
       " 'A5T2G3C0',\n",
       " 'A5T3G0C2',\n",
       " 'A5T3G1C1',\n",
       " 'A5T3G2C0',\n",
       " 'A5T4G0C1',\n",
       " 'A5T4G1C0',\n",
       " 'A5T5G0C0',\n",
       " 'A6T0G0C4',\n",
       " 'A6T0G1C3',\n",
       " 'A6T0G2C2',\n",
       " 'A6T0G3C1',\n",
       " 'A6T0G4C0',\n",
       " 'A6T1G0C3',\n",
       " 'A6T1G1C2',\n",
       " 'A6T1G2C1',\n",
       " 'A6T1G3C0',\n",
       " 'A6T2G0C2',\n",
       " 'A6T2G1C1',\n",
       " 'A6T2G2C0',\n",
       " 'A6T3G0C1',\n",
       " 'A6T3G1C0',\n",
       " 'A6T4G0C0',\n",
       " 'A7T0G0C3',\n",
       " 'A7T0G1C2',\n",
       " 'A7T0G2C1',\n",
       " 'A7T0G3C0',\n",
       " 'A7T1G0C2',\n",
       " 'A7T1G1C1',\n",
       " 'A7T1G2C0',\n",
       " 'A7T2G0C1',\n",
       " 'A7T2G1C0',\n",
       " 'A7T3G0C0',\n",
       " 'A8T0G0C2',\n",
       " 'A8T0G1C1',\n",
       " 'A8T0G2C0',\n",
       " 'A8T1G0C1',\n",
       " 'A8T1G1C0',\n",
       " 'A8T2G0C0',\n",
       " 'A9T0G0C1',\n",
       " 'A9T0G1C0',\n",
       " 'A9T1G0C0',\n",
       " 'A10T0G0C0',\n",
       " 'gcd',\n",
       " 'mean',\n",
       " 'std',\n",
       " 'min',\n",
       " 'max',\n",
       " 'median',\n",
       " '25%',\n",
       " '75%',\n",
       " 'skew',\n",
       " 'kurt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE = 13\n",
    "FOLDS = 4\n",
    "TARGET = 'target'\n",
    "FEATURES = [col for col in train.columns if col not in ['row_id', TARGET]]\n",
    "\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的変数（target）を数値に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train[TARGET] = encoder.fit_transform(train[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>A0T0G0C10</th>\n",
       "      <th>A0T0G1C9</th>\n",
       "      <th>A0T0G2C8</th>\n",
       "      <th>A0T0G3C7</th>\n",
       "      <th>A0T0G4C6</th>\n",
       "      <th>A0T0G5C5</th>\n",
       "      <th>A0T0G6C4</th>\n",
       "      <th>A0T0G7C3</th>\n",
       "      <th>A0T0G8C2</th>\n",
       "      <th>...</th>\n",
       "      <th>gcd</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>25%</th>\n",
       "      <th>75%</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10000</td>\n",
       "      <td>3496.503497</td>\n",
       "      <td>7422.936598</td>\n",
       "      <td>0</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.393523</td>\n",
       "      <td>5.856459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3496.503497</td>\n",
       "      <td>5211.827475</td>\n",
       "      <td>0</td>\n",
       "      <td>26000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>2.242743</td>\n",
       "      <td>5.173521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>243</td>\n",
       "      <td>468</td>\n",
       "      <td>510</td>\n",
       "      <td>443</td>\n",
       "      <td>239</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3496.503497</td>\n",
       "      <td>4899.271608</td>\n",
       "      <td>0</td>\n",
       "      <td>24155</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>321.50</td>\n",
       "      <td>4402.5</td>\n",
       "      <td>2.086805</td>\n",
       "      <td>4.169623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>359</td>\n",
       "      <td>692</td>\n",
       "      <td>762</td>\n",
       "      <td>596</td>\n",
       "      <td>311</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3496.503497</td>\n",
       "      <td>4763.599809</td>\n",
       "      <td>0</td>\n",
       "      <td>24472</td>\n",
       "      <td>1445.5</td>\n",
       "      <td>390.25</td>\n",
       "      <td>4583.5</td>\n",
       "      <td>2.016652</td>\n",
       "      <td>3.827831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10000</td>\n",
       "      <td>3496.503497</td>\n",
       "      <td>8101.006328</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.147624</td>\n",
       "      <td>12.195877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  A0T0G0C10  A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  A0T0G5C5  \\\n",
       "0       0          0         0         0         0         0         0   \n",
       "1       1          0         0         0      1000         0      1000   \n",
       "2       2          0         8        50       243       468       510   \n",
       "3       3          1         4        55       359       692       762   \n",
       "4       4          0         0         0         0         0         0   \n",
       "\n",
       "   A0T0G6C4  A0T0G7C3  A0T0G8C2  ...    gcd         mean          std  min  \\\n",
       "0         0         0         0  ...  10000  3496.503497  7422.936598    0   \n",
       "1         0         0         0  ...   1000  3496.503497  5211.827475    0   \n",
       "2       443       239        44  ...      1  3496.503497  4899.271608    0   \n",
       "3       596       311        40  ...      1  3496.503497  4763.599809    0   \n",
       "4         0         0         0  ...  10000  3496.503497  8101.006328    0   \n",
       "\n",
       "     max  median     25%     75%      skew       kurt  \n",
       "0  40000     0.0    0.00     0.0  2.393523   5.856459  \n",
       "1  26000  1000.0    0.00  4750.0  2.242743   5.173521  \n",
       "2  24155  1340.0  321.50  4402.5  2.086805   4.169623  \n",
       "3  24472  1445.5  390.25  4583.5  2.016652   3.827831  \n",
       "4  50000     0.0    0.00     0.0  3.147624  12.195877  \n",
       "\n",
       "[5 rows x 298 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123993, 298)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testにターゲット列を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[TARGET] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123993, 298) (100000, 298)\n",
      "Fold 1 accuracy score: 0.9741\n",
      "Fold 2 accuracy score: 0.9755\n",
      "Fold 3 accuracy score: 0.9762\n",
      "Fold 4 accuracy score: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qr/28b40stn0vvfvznrz793zqgw0000gn/T/ipykernel_32681/468061311.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gcd_split_test_id[TARGET] = y_proba_tuned\n"
     ]
    }
   ],
   "source": [
    "predictions, scores, submissions = {}, {}, {}\n",
    "result = {}\n",
    "feature_importance = []\n",
    "\n",
    "k = StratifiedKFold(n_splits = FOLDS, random_state = RANDOM_STATE, shuffle = True)\n",
    "\n",
    "gcd_split_train = train[train['gcd'] >= 1]\n",
    "gcd_split_test = test[test['gcd'] >= 1]\n",
    "\n",
    "scores[f'gcd_score'] = []\n",
    "predictions[f'gcd_pred'] = []\n",
    "\n",
    "gcd_split_test_id = gcd_split_test[['row_id', TARGET]]\n",
    "\n",
    "print(gcd_split_train.shape, gcd_split_test.shape)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(k.split(gcd_split_train[FEATURES], gcd_split_train[TARGET])):\n",
    "\n",
    "    ### データセット作成\n",
    "    X_train, X_val = gcd_split_train.iloc[train_idx][FEATURES], gcd_split_train.iloc[val_idx][FEATURES]\n",
    "    y_train, y_val = gcd_split_train[TARGET].iloc[train_idx] , gcd_split_train[TARGET].iloc[val_idx]\n",
    "\n",
    "    ### 学習\n",
    "    #model = ExtraTreesClassifier(n_estimators=1111, n_jobs=-1, class_weight={2:3, 3:4, 8:3, 9:3})\n",
    "    model = ExtraTreesClassifier(n_estimators=1111, n_jobs=-1)\n",
    "    model.fit(X_train, y_train, sample_weight=X_train['gcd'])\n",
    "\n",
    "    ### 推論（validation）\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_score = accuracy_score(y_val, val_pred)\n",
    "    scores[f'gcd_score'].append(val_score)\n",
    "    result[f'Fold{i+1}_yval'] = y_val\n",
    "    result[f'Fold{i+1}_pred'] = val_pred\n",
    "\n",
    "    print(f'Fold {i+1} accuracy score: {round(val_score, 4)}')\n",
    "\n",
    "    ### feature importance\n",
    "    feat_imp = pd.DataFrame(index=FEATURES, data=model.feature_importances_, columns=[f'Fold{i+1}_importance'])\n",
    "    feature_importance.append(feat_imp)\n",
    "\n",
    "    ### 推論（test）\n",
    "    predictions[f'gcd_pred'].append(model.predict_proba(gcd_split_test[FEATURES]))\n",
    "\n",
    "y_proba = sum(predictions[f'gcd_pred']) / len(predictions[f'gcd_pred'])\n",
    "# y_proba += np.array([0, 0, 0.025, 0.045, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "y_proba_tuned = encoder.inverse_transform(np.argmax(y_proba, axis=1))\n",
    "gcd_split_test_id[TARGET] = y_proba_tuned\n",
    "submissions[f'gcd_large'] = gcd_split_test_id\n",
    "\n",
    "#submissions['merged'] = pd.concat([submissions['gcd_small'], submissions['gcd_large']], axis=0)\n",
    "#submissions['merged'] = submissions['merged'].sort_values('row_id')\n",
    "\n",
    "#print('')\n",
    "#print(f'Mean accuracy - {round(np.mean(scores), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_dict = {}\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    if fold == 0:\n",
    "        y_vals = result[f'Fold{fold+1}_yval']\n",
    "        preds  = result[f'Fold{fold+1}_pred']\n",
    "    else:\n",
    "        y_vals = pd.concat([y_vals, result[f'Fold{fold+1}_yval']], axis=0)\n",
    "        preds = np.concatenate([preds, result[f'Fold{fold+1}_pred']], axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "cm_dict[f'large'] = confusion_matrix(y_vals, preds, normalize='true')\n",
    "sns.heatmap(cm_dict[f'large'], annot=True, cmap='Blues')\n",
    "plt.title(f'confusion matrix in gcd = large')\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature importance\n",
    "feat_imp = pd.concat(feature_importance, axis=1)\n",
    "\n",
    "feat_imp_gcd_large = feat_imp[['Fold1_importance', 'Fold2_importance', 'Fold3_importance', 'Fold4_importance']]\n",
    "feat_imp_gcd_large.sort_values('Fold1_importance').tail(10).plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_gcd_large.sort_values('Fold1_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions['merged'].to_csv(f\"../data/submission/nb{NB}_ExtraTree.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_dict['GCD1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gcd in np.unique(train['gcd']):\n",
    "    if gcd < 100:\n",
    "        continue\n",
    "    for fold in range(FOLDS):\n",
    "        plt.figure(figsize=(15,10))\n",
    "        cm = confusion_matrix(result[f'GCD{gcd}_Fold{fold+1}_yval'], result[f'GCD{gcd}_Fold{fold+1}_pred'])\n",
    "        display(accuracy_score(result[f'GCD{gcd}_Fold{fold+1}_yval'], result[f'GCD{gcd}_Fold{fold+1}_pred']))\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature importance\n",
    "feat_imp = pd.concat(feature_importance, axis=1)\n",
    "\n",
    "feat_imp_gcd1 = feat_imp[['GCD1_Fold1_importance', 'GCD1_Fold2_importance', 'GCD1_Fold3_importance', 'GCD1_Fold4_importance']]\n",
    "feat_imp_gcd1.sort_values('GCD1_Fold1_importance').tail(10).plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_gcd10 = feat_imp[['GCD10_Fold1_importance', 'GCD10_Fold2_importance', 'GCD10_Fold3_importance', 'GCD10_Fold4_importance']]\n",
    "feat_imp_gcd10.sort_values('GCD10_Fold1_importance').tail(10).plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_gcd1000 = feat_imp[['GCD1000_Fold1_importance', 'GCD1000_Fold2_importance', 'GCD1000_Fold3_importance', 'GCD1000_Fold4_importance']]\n",
    "feat_imp_gcd1000.sort_values('GCD1000_Fold1_importance').tail(10).plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_gcd10000 = feat_imp[['GCD10000_Fold1_importance', 'GCD10000_Fold2_importance', 'GCD10000_Fold3_importance', 'GCD10000_Fold4_importance']]\n",
    "feat_imp_gcd10000.sort_values('GCD10000_Fold1_importance').tail(10).plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp.sort_values('1_importance').tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_fixed_params = {\n",
    "    'objective' : 'multiclass',\n",
    "    'metric' : 'multi_logloss',\n",
    "    \"n_estimators\": 3000,\n",
    "    'learning_rate': 0.1,\n",
    "}\n",
    "\n",
    "#fit_params = {\"early_stopping_rounds\": 100,\n",
    "#            \"eval_set\": [[X_test, y_test]]}\n",
    "\n",
    "\n",
    "# LightGBM parameters\n",
    "lgb_param_grid = {\n",
    "                 #'learning_rate': [0.1, 0.05],\n",
    "                 'num_leaves' : [63],\n",
    "                 #'num_leaves' : [12, 15, 18],\n",
    "                 'max_depth'  : [21],\n",
    "                 #'max_depth'  : [6, 9, 15],\n",
    "                 #'min_gain_to_split' : [0, 0.1, 0.2],\n",
    "                 #'feature_fraction' : [0.5, 0.7, 1],\n",
    "                 #'bagging_fraction' : [0.7, 0.9, 1],\n",
    "                 #'min_sum_hessian_in_leaf' : [1, 2, 4],\n",
    "                }\n",
    "\n",
    "callbacks = [early_stopping(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_predictions = []\n",
    "lgb_scores = []\n",
    "lgb_feature_importance = []\n",
    "lgb_result = {}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n",
    "\n",
    "    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    ### データセット作成\n",
    "    X_train, X_val = train.iloc[train_idx][FEATURES], train.iloc[val_idx][FEATURES]\n",
    "    y_train, y_val = train[TARGET].iloc[train_idx] , train[TARGET].iloc[val_idx]\n",
    "\n",
    "    ### 学習\n",
    "    lgb_model = LGBMClassifier(**lgb_fixed_params)\n",
    "\n",
    "    # gs = GridSearchCV(model, param_grid=lgb_param_grid, fit_params=lgb_fixed_params, cv=FOLDS, n_jobs=-1, verbose=2)\n",
    "    gs_lgb = GridSearchCV(lgb_model, param_grid=lgb_param_grid, cv=FOLDS, n_jobs=-1, verbose=2)\n",
    "    gs_lgb.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=0, callbacks=callbacks)\n",
    "\n",
    "    #model.fit(X_train, y_train,verbose=0)\n",
    "    #model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=0, callbacks=callbacks)\n",
    "\n",
    "    ### 結果格納\n",
    "    lgb_result[f'Fold{fold}_best_estimator'] = gs_lgb.best_estimator_\n",
    "    lgb_result[f'Fold{fold}_best_score'] = gs_lgb.best_score_\n",
    "    lgb_result[f'Fold{fold}_best_grid_params'] = gs_lgb.best_params_\n",
    "    lgb_result[f'Fold{fold}_best_all_params'] = lgb_result[f'Fold{fold}_best_estimator'].get_params()\n",
    "    lgb_result[f'Fold{fold}_cv_result'] = pd.DataFrame(gs_lgb.cv_results_)\n",
    "\n",
    "    ### Best Score\n",
    "    print(f\"Best Score: {gs_lgb.best_score_}\")\n",
    "    print(f\"Best Param: {gs_lgb.best_params_}\")\n",
    "\n",
    "    ### 推論（validation）\n",
    "    preds_val = gs_lgb.predict(X_val)\n",
    "    acc = accuracy_score(y_val, preds_val)\n",
    "    lgb_scores.append(acc)\n",
    "\n",
    "    ### 結果格納\n",
    "    lgb_result[f'Fold{fold}_preds_val'] = preds_val\n",
    "    lgb_result[f'Fold{fold}_y_val'] = y_val\n",
    "    lgb_result[f'Fold{fold}_acc'] = acc\n",
    "\n",
    "    ### feature importance\n",
    "    feat_imp = pd.DataFrame(index=FEATURES, data=lgb_result[f'Fold{fold}_best_estimator'].feature_importances_, columns=[f'{fold}_importance'])\n",
    "    lgb_feature_importance.append(feat_imp)\n",
    "\n",
    "    ### 推論（test）\n",
    "    test_preds = gs_lgb.predict(test[FEATURES])\n",
    "    lgb_predictions.append(test_preds)\n",
    "\n",
    "    ### 結果表示\n",
    "    run_time = time.time() - start_time\n",
    "    print(f\"Fold={fold+1}, Accuracy: {acc:.5f}, Run Time: {run_time:.2f}s\")\n",
    "\n",
    "print(10*\"=\", \"Cross Validation finished.\", 10*\"=\")\n",
    "print(\"Mean Accuracy :\", np.mean(lgb_scores))\n",
    "print(lgb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(FOLDS):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    cm = confusion_matrix(lgb_result[f'Fold{fold}_y_val'], lgb_result[f'Fold{fold}_preds_val'])\n",
    "    display(accuracy_score(lgb_result[f'Fold{fold}_y_val'], lgb_result[f'Fold{fold}_preds_val']))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_fis_df = pd.concat(lgb_feature_importance, axis=1).head(15)\n",
    "lgbm_fis_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_submission = submission.copy()\n",
    "lgb_submission[TARGET] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(lgb_predictions),axis = 1)[0]).astype('int'))\n",
    "#lgb_submission[TARGET] = np.squeeze(mode(np.column_stack(lgb_predictions),axis = 1)[0]).astype('int')\n",
    "### 列方向にリストを行列化して、各行の最頻値をとって、１次元の配列は削除して、intにして、数値をラベルに戻している\n",
    "\n",
    "lgb_submission.to_csv(f\"../data/submission/nb{NB}_LGBM.csv\",index=False)\n",
    "lgb_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\"early_stopping_rounds\": 100,\n",
    "              \"eval_set\": [[X_test, y_test]]}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "gs = GridSearchCV(xgb_model,\n",
    "                  params,\n",
    "                  fit_params=fit_params,\n",
    "                  cv=10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "def GridSearchCV_XGB_early_stoppping(param_grid, param_fixed, scorer, cv, X, y):\n",
    "    \"\"\"This function performs grid search for the best set of parameters of XGBoost model with early stopping.\n",
    "\n",
    "    Args:\n",
    "        param_grid (dict): The parameter ranges for which the function searches.\n",
    "        param_fixed (dict): The fitting parameters for XGBoost.\n",
    "        scorer (_PredictScorer): The sklearn's scorer instance.\n",
    "        cv (model_selection._split): The sklearn's split instance.\n",
    "        X (DataFrame): The input data matrix.\n",
    "        y (Series): The ground truth label.\n",
    "\n",
    "    Returns:\n",
    "        dict: The best set of parameters found via grid search.\n",
    "    \"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_numpy()\n",
    "\n",
    "    param_names, param_values = zip(*list(param_grid.items()))\n",
    "\n",
    "    cv_best_iterations = defaultdict(list)\n",
    "    cv_results = defaultdict(list)\n",
    "\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        gscv_x_train, gscv_x_val = X[train_index], X[test_index]\n",
    "        gscv_y_train, gscv_y_val = y[train_index], y[test_index]\n",
    "\n",
    "        param_fixed_cv = deepcopy(param_fixed)\n",
    "        param_fixed_cv['eval_set'] = [(gscv_x_val, gscv_y_val)]\n",
    "\n",
    "        for value_combination in product(*param_values):\n",
    "            param_grid_cv = tuple(zip(param_names, value_combination))\n",
    "            xgboost = XGBRegressor(**dict(param_grid_cv))\n",
    "\n",
    "            xgboost.fit(gscv_x_train, gscv_y_train, **param_fixed_cv)\n",
    "            if 'early_stopping_rounds' not in param_fixed_cv:\n",
    "                best_iteration = xgboost.get_num_boosting_rounds()\n",
    "            else:\n",
    "                best_iteration = xgboost.best_iteration\n",
    "            cv_best_iterations[param_grid_cv].append(best_iteration)\n",
    "\n",
    "            score = scorer(xgboost, gscv_x_val, gscv_y_val)\n",
    "            cv_results[param_grid_cv].append(score)\n",
    "\n",
    "    best_params_xgb, score_list = max(cv_results.items(), key=lambda x: np.array(x[1]).mean())\n",
    "\n",
    "    # Note that our XGBoost model may stop early,\n",
    "    # so we calculate the mean of the actual number of estimators in each fold,\n",
    "    # in place of the originally planned n_estimators after finishing cross validation.\n",
    "    n_estimators = int(round(np.array(cv_best_iterations[best_params_xgb]).mean()))\n",
    "\n",
    "    best_params_xgb = dict(best_params_xgb)\n",
    "    best_params_xgb['n_estimators'] = n_estimators\n",
    "\n",
    "    print (\"Best score: {:.3f}\".format(np.array(score_list).mean()))\n",
    "    print (\"Best Parameters: {}\".format(best_params_xgb))\n",
    "\n",
    "    return best_params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = train.head(10)\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_1_df = tmp_df[tmp_df['gcd'] == 1]\n",
    "tmp_oth_df = tmp_df[tmp_df['gcd'] != 1]\n",
    "tmp_oth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_new_df = pd.concat([tmp_1_df, tmp_oth_df], axis=0)\n",
    "tmp_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sort_df = tmp_new_df.sort_values('row_id')\n",
    "tmp_sort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df[tmp_df['row_id'].isin(tmp_1_df['row_id'])].loc[:, 'gcd'] = 2\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc8a78a13283e3ba74119858067a74c2c7a55702e09c935fdd8fe4b244251524"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
