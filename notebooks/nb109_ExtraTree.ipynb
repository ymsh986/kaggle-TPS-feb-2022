{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPS-Feb-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '109'\n",
    "dataset_NB = '004'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import mode\n",
    "import time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier, early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "##### Load train and Test set\n",
    "train = pd.read_pickle(f\"../data/processed/nb{dataset_NB}_train.pkl\", compression='zip')\n",
    "test = pd.read_pickle(f\"../data/processed/nb{dataset_NB}_test.pkl\", compression='zip')\n",
    "\n",
    "submission = pd.read_csv('../data/raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train)\n",
    "test_id = test['row_id']\n",
    "\n",
    "#dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n",
    "# reset_index: indexを0から順に振り直す\n",
    "# drop: Falseの場合、元のindexが「index」列が新たに生成されて残る。Trueの場合「index」列は作られない。\n",
    "\n",
    "#dataset = dataset.drop(columns=['row_id'])\n",
    "#train = train.drop(columns=['row_id'])\n",
    "\n",
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A0T0G0C10',\n",
       " 'A0T0G1C9',\n",
       " 'A0T0G2C8',\n",
       " 'A0T0G3C7',\n",
       " 'A0T0G4C6',\n",
       " 'A0T0G5C5',\n",
       " 'A0T0G6C4',\n",
       " 'A0T0G7C3',\n",
       " 'A0T0G8C2',\n",
       " 'A0T0G9C1',\n",
       " 'A0T0G10C0',\n",
       " 'A0T1G0C9',\n",
       " 'A0T1G1C8',\n",
       " 'A0T1G2C7',\n",
       " 'A0T1G3C6',\n",
       " 'A0T1G4C5',\n",
       " 'A0T1G5C4',\n",
       " 'A0T1G6C3',\n",
       " 'A0T1G7C2',\n",
       " 'A0T1G8C1',\n",
       " 'A0T1G9C0',\n",
       " 'A0T2G0C8',\n",
       " 'A0T2G1C7',\n",
       " 'A0T2G2C6',\n",
       " 'A0T2G3C5',\n",
       " 'A0T2G4C4',\n",
       " 'A0T2G5C3',\n",
       " 'A0T2G6C2',\n",
       " 'A0T2G7C1',\n",
       " 'A0T2G8C0',\n",
       " 'A0T3G0C7',\n",
       " 'A0T3G1C6',\n",
       " 'A0T3G2C5',\n",
       " 'A0T3G3C4',\n",
       " 'A0T3G4C3',\n",
       " 'A0T3G5C2',\n",
       " 'A0T3G6C1',\n",
       " 'A0T3G7C0',\n",
       " 'A0T4G0C6',\n",
       " 'A0T4G1C5',\n",
       " 'A0T4G2C4',\n",
       " 'A0T4G3C3',\n",
       " 'A0T4G4C2',\n",
       " 'A0T4G5C1',\n",
       " 'A0T4G6C0',\n",
       " 'A0T5G0C5',\n",
       " 'A0T5G1C4',\n",
       " 'A0T5G2C3',\n",
       " 'A0T5G3C2',\n",
       " 'A0T5G4C1',\n",
       " 'A0T5G5C0',\n",
       " 'A0T6G0C4',\n",
       " 'A0T6G1C3',\n",
       " 'A0T6G2C2',\n",
       " 'A0T6G3C1',\n",
       " 'A0T6G4C0',\n",
       " 'A0T7G0C3',\n",
       " 'A0T7G1C2',\n",
       " 'A0T7G2C1',\n",
       " 'A0T7G3C0',\n",
       " 'A0T8G0C2',\n",
       " 'A0T8G1C1',\n",
       " 'A0T8G2C0',\n",
       " 'A0T9G0C1',\n",
       " 'A0T9G1C0',\n",
       " 'A0T10G0C0',\n",
       " 'A1T0G0C9',\n",
       " 'A1T0G1C8',\n",
       " 'A1T0G2C7',\n",
       " 'A1T0G3C6',\n",
       " 'A1T0G4C5',\n",
       " 'A1T0G5C4',\n",
       " 'A1T0G6C3',\n",
       " 'A1T0G7C2',\n",
       " 'A1T0G8C1',\n",
       " 'A1T0G9C0',\n",
       " 'A1T1G0C8',\n",
       " 'A1T1G1C7',\n",
       " 'A1T1G2C6',\n",
       " 'A1T1G3C5',\n",
       " 'A1T1G4C4',\n",
       " 'A1T1G5C3',\n",
       " 'A1T1G6C2',\n",
       " 'A1T1G7C1',\n",
       " 'A1T1G8C0',\n",
       " 'A1T2G0C7',\n",
       " 'A1T2G1C6',\n",
       " 'A1T2G2C5',\n",
       " 'A1T2G3C4',\n",
       " 'A1T2G4C3',\n",
       " 'A1T2G5C2',\n",
       " 'A1T2G6C1',\n",
       " 'A1T2G7C0',\n",
       " 'A1T3G0C6',\n",
       " 'A1T3G1C5',\n",
       " 'A1T3G2C4',\n",
       " 'A1T3G3C3',\n",
       " 'A1T3G4C2',\n",
       " 'A1T3G5C1',\n",
       " 'A1T3G6C0',\n",
       " 'A1T4G0C5',\n",
       " 'A1T4G1C4',\n",
       " 'A1T4G2C3',\n",
       " 'A1T4G3C2',\n",
       " 'A1T4G4C1',\n",
       " 'A1T4G5C0',\n",
       " 'A1T5G0C4',\n",
       " 'A1T5G1C3',\n",
       " 'A1T5G2C2',\n",
       " 'A1T5G3C1',\n",
       " 'A1T5G4C0',\n",
       " 'A1T6G0C3',\n",
       " 'A1T6G1C2',\n",
       " 'A1T6G2C1',\n",
       " 'A1T6G3C0',\n",
       " 'A1T7G0C2',\n",
       " 'A1T7G1C1',\n",
       " 'A1T7G2C0',\n",
       " 'A1T8G0C1',\n",
       " 'A1T8G1C0',\n",
       " 'A1T9G0C0',\n",
       " 'A2T0G0C8',\n",
       " 'A2T0G1C7',\n",
       " 'A2T0G2C6',\n",
       " 'A2T0G3C5',\n",
       " 'A2T0G4C4',\n",
       " 'A2T0G5C3',\n",
       " 'A2T0G6C2',\n",
       " 'A2T0G7C1',\n",
       " 'A2T0G8C0',\n",
       " 'A2T1G0C7',\n",
       " 'A2T1G1C6',\n",
       " 'A2T1G2C5',\n",
       " 'A2T1G3C4',\n",
       " 'A2T1G4C3',\n",
       " 'A2T1G5C2',\n",
       " 'A2T1G6C1',\n",
       " 'A2T1G7C0',\n",
       " 'A2T2G0C6',\n",
       " 'A2T2G1C5',\n",
       " 'A2T2G2C4',\n",
       " 'A2T2G3C3',\n",
       " 'A2T2G4C2',\n",
       " 'A2T2G5C1',\n",
       " 'A2T2G6C0',\n",
       " 'A2T3G0C5',\n",
       " 'A2T3G1C4',\n",
       " 'A2T3G2C3',\n",
       " 'A2T3G3C2',\n",
       " 'A2T3G4C1',\n",
       " 'A2T3G5C0',\n",
       " 'A2T4G0C4',\n",
       " 'A2T4G1C3',\n",
       " 'A2T4G2C2',\n",
       " 'A2T4G3C1',\n",
       " 'A2T4G4C0',\n",
       " 'A2T5G0C3',\n",
       " 'A2T5G1C2',\n",
       " 'A2T5G2C1',\n",
       " 'A2T5G3C0',\n",
       " 'A2T6G0C2',\n",
       " 'A2T6G1C1',\n",
       " 'A2T6G2C0',\n",
       " 'A2T7G0C1',\n",
       " 'A2T7G1C0',\n",
       " 'A2T8G0C0',\n",
       " 'A3T0G0C7',\n",
       " 'A3T0G1C6',\n",
       " 'A3T0G2C5',\n",
       " 'A3T0G3C4',\n",
       " 'A3T0G4C3',\n",
       " 'A3T0G5C2',\n",
       " 'A3T0G6C1',\n",
       " 'A3T0G7C0',\n",
       " 'A3T1G0C6',\n",
       " 'A3T1G1C5',\n",
       " 'A3T1G2C4',\n",
       " 'A3T1G3C3',\n",
       " 'A3T1G4C2',\n",
       " 'A3T1G5C1',\n",
       " 'A3T1G6C0',\n",
       " 'A3T2G0C5',\n",
       " 'A3T2G1C4',\n",
       " 'A3T2G2C3',\n",
       " 'A3T2G3C2',\n",
       " 'A3T2G4C1',\n",
       " 'A3T2G5C0',\n",
       " 'A3T3G0C4',\n",
       " 'A3T3G1C3',\n",
       " 'A3T3G2C2',\n",
       " 'A3T3G3C1',\n",
       " 'A3T3G4C0',\n",
       " 'A3T4G0C3',\n",
       " 'A3T4G1C2',\n",
       " 'A3T4G2C1',\n",
       " 'A3T4G3C0',\n",
       " 'A3T5G0C2',\n",
       " 'A3T5G1C1',\n",
       " 'A3T5G2C0',\n",
       " 'A3T6G0C1',\n",
       " 'A3T6G1C0',\n",
       " 'A3T7G0C0',\n",
       " 'A4T0G0C6',\n",
       " 'A4T0G1C5',\n",
       " 'A4T0G2C4',\n",
       " 'A4T0G3C3',\n",
       " 'A4T0G4C2',\n",
       " 'A4T0G5C1',\n",
       " 'A4T0G6C0',\n",
       " 'A4T1G0C5',\n",
       " 'A4T1G1C4',\n",
       " 'A4T1G2C3',\n",
       " 'A4T1G3C2',\n",
       " 'A4T1G4C1',\n",
       " 'A4T1G5C0',\n",
       " 'A4T2G0C4',\n",
       " 'A4T2G1C3',\n",
       " 'A4T2G2C2',\n",
       " 'A4T2G3C1',\n",
       " 'A4T2G4C0',\n",
       " 'A4T3G0C3',\n",
       " 'A4T3G1C2',\n",
       " 'A4T3G2C1',\n",
       " 'A4T3G3C0',\n",
       " 'A4T4G0C2',\n",
       " 'A4T4G1C1',\n",
       " 'A4T4G2C0',\n",
       " 'A4T5G0C1',\n",
       " 'A4T5G1C0',\n",
       " 'A4T6G0C0',\n",
       " 'A5T0G0C5',\n",
       " 'A5T0G1C4',\n",
       " 'A5T0G2C3',\n",
       " 'A5T0G3C2',\n",
       " 'A5T0G4C1',\n",
       " 'A5T0G5C0',\n",
       " 'A5T1G0C4',\n",
       " 'A5T1G1C3',\n",
       " 'A5T1G2C2',\n",
       " 'A5T1G3C1',\n",
       " 'A5T1G4C0',\n",
       " 'A5T2G0C3',\n",
       " 'A5T2G1C2',\n",
       " 'A5T2G2C1',\n",
       " 'A5T2G3C0',\n",
       " 'A5T3G0C2',\n",
       " 'A5T3G1C1',\n",
       " 'A5T3G2C0',\n",
       " 'A5T4G0C1',\n",
       " 'A5T4G1C0',\n",
       " 'A5T5G0C0',\n",
       " 'A6T0G0C4',\n",
       " 'A6T0G1C3',\n",
       " 'A6T0G2C2',\n",
       " 'A6T0G3C1',\n",
       " 'A6T0G4C0',\n",
       " 'A6T1G0C3',\n",
       " 'A6T1G1C2',\n",
       " 'A6T1G2C1',\n",
       " 'A6T1G3C0',\n",
       " 'A6T2G0C2',\n",
       " 'A6T2G1C1',\n",
       " 'A6T2G2C0',\n",
       " 'A6T3G0C1',\n",
       " 'A6T3G1C0',\n",
       " 'A6T4G0C0',\n",
       " 'A7T0G0C3',\n",
       " 'A7T0G1C2',\n",
       " 'A7T0G2C1',\n",
       " 'A7T0G3C0',\n",
       " 'A7T1G0C2',\n",
       " 'A7T1G1C1',\n",
       " 'A7T1G2C0',\n",
       " 'A7T2G0C1',\n",
       " 'A7T2G1C0',\n",
       " 'A7T3G0C0',\n",
       " 'A8T0G0C2',\n",
       " 'A8T0G1C1',\n",
       " 'A8T0G2C0',\n",
       " 'A8T1G0C1',\n",
       " 'A8T1G1C0',\n",
       " 'A8T2G0C0',\n",
       " 'A9T0G0C1',\n",
       " 'A9T0G1C0',\n",
       " 'A9T1G0C0',\n",
       " 'A10T0G0C0',\n",
       " 'mean',\n",
       " 'std',\n",
       " 'min',\n",
       " 'max',\n",
       " 'median',\n",
       " '25%',\n",
       " '75%',\n",
       " 'skew',\n",
       " 'kurt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE = 13\n",
    "FOLDS = 4\n",
    "TARGET = 'target'\n",
    "FEATURES = [col for col in train.columns if col not in ['row_id', TARGET]]\n",
    "\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的変数（target）を数値に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train[TARGET] = encoder.fit_transform(train[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>A0T0G0C10</th>\n",
       "      <th>A0T0G1C9</th>\n",
       "      <th>A0T0G2C8</th>\n",
       "      <th>A0T0G3C7</th>\n",
       "      <th>A0T0G4C6</th>\n",
       "      <th>A0T0G5C5</th>\n",
       "      <th>A0T0G6C4</th>\n",
       "      <th>A0T0G7C3</th>\n",
       "      <th>A0T0G8C2</th>\n",
       "      <th>...</th>\n",
       "      <th>target</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>25%</th>\n",
       "      <th>75%</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2.767028e-17</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>1.307963</td>\n",
       "      <td>4.111766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.129996e-17</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>4.551135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.785171e-18</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>-0.002587</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.415096</td>\n",
       "      <td>4.174590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.632568e-08</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.829865e-19</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>-0.395986</td>\n",
       "      <td>4.501727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.872491e-17</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>0.037984</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>1.250485</td>\n",
       "      <td>6.388081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     A0T0G0C10  A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  A0T0G5C5  \\\n",
       "0       0 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n",
       "1       1 -9.536743e-07 -0.000010 -0.000043  0.000886 -0.000200  0.000760   \n",
       "2       2 -9.536743e-07 -0.000002  0.000007  0.000129  0.000268  0.000270   \n",
       "3       3  4.632568e-08 -0.000006  0.000012  0.000245  0.000492  0.000522   \n",
       "4       4 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n",
       "\n",
       "   A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  target          mean       std  \\\n",
       "0 -0.000200 -0.000114 -0.000043  ...       9  2.767028e-17  0.005643   \n",
       "1 -0.000200 -0.000114 -0.000043  ...       6  1.129996e-17  0.001751   \n",
       "2  0.000243  0.000125  0.000001  ...       6 -1.785171e-18  0.000601   \n",
       "3  0.000396  0.000197 -0.000003  ...       6 -4.829865e-19  0.001160   \n",
       "4 -0.000200 -0.000114 -0.000043  ...       2  2.872491e-17  0.007117   \n",
       "\n",
       "        min       max    median       25%       75%      skew      kurt  \n",
       "0 -0.014033  0.023992 -0.000687 -0.002403 -0.000043  1.307963  4.111766  \n",
       "1 -0.005016  0.008984 -0.000086 -0.000801  0.000796  0.696087  4.551135  \n",
       "2 -0.002587  0.002327  0.000015 -0.000124  0.000201 -0.415096  4.174590  \n",
       "3 -0.005403  0.004602  0.000019 -0.000230  0.000394 -0.395986  4.501727  \n",
       "4 -0.024033  0.037984 -0.000343 -0.002403 -0.000043  1.250485  6.388081  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123993, 297)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy score: 0.9741\n",
      "Fold 2 accuracy score: 0.9751\n",
      "Fold 3 accuracy score: 0.9767\n",
      "Fold 4 accuracy score: 0.9745\n",
      "\n",
      "Mean accuracy - 0.9751\n"
     ]
    }
   ],
   "source": [
    "predictions, scores = [], []\n",
    "\n",
    "k = StratifiedKFold(n_splits = FOLDS, random_state = RANDOM_STATE, shuffle = True)\n",
    "for i, (train_idx, val_idx) in enumerate(k.split(train[FEATURES], train[TARGET])):\n",
    "\n",
    "    X_train, X_val = train.iloc[train_idx][FEATURES], train.iloc[val_idx][FEATURES]\n",
    "    y_train, y_val = train[TARGET].iloc[train_idx] , train[TARGET].iloc[val_idx]\n",
    "\n",
    "    model = ExtraTreesClassifier(n_estimators=1111, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_score = accuracy_score(y_val, val_pred)\n",
    "    print(f'Fold {i+1} accuracy score: {round(val_score, 4)}')\n",
    "\n",
    "    scores.append(val_score)\n",
    "    predictions.append(model.predict_proba(test[FEATURES]))\n",
    "\n",
    "print('')\n",
    "print(f'Mean accuracy - {round(np.mean(scores), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>Escherichia_fergusonii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>Enterococcus_hirae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>Staphylococcus_aureus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                  target\n",
       "0  200000  Escherichia_fergusonii\n",
       "1  200001     Salmonella_enterica\n",
       "2  200002      Enterococcus_hirae\n",
       "3  200003     Salmonella_enterica\n",
       "4  200004   Staphylococcus_aureus"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = sum(predictions) / len(predictions)\n",
    "y_proba += np.array([0, 0, 0.025, 0.045, 0, 0, 0, 0, 0, 0])\n",
    "y_pred_tuned = encoder.inverse_transform(np.argmax(y_proba, axis=1))\n",
    "\n",
    "extratree_submission = submission.copy()\n",
    "extratree_submission[TARGET] = y_pred_tuned\n",
    "\n",
    "extratree_submission.to_csv(f\"../data/submission/nb{NB}_ExtraTree.csv\",index=False)\n",
    "extratree_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 1111,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_fixed_params = {\n",
    "    'objective' : 'multiclass',\n",
    "    'metric' : 'multi_logloss',\n",
    "    \"n_estimators\": 3000,\n",
    "    'learning_rate': 0.1,\n",
    "}\n",
    "\n",
    "#fit_params = {\"early_stopping_rounds\": 100,\n",
    "#            \"eval_set\": [[X_test, y_test]]}\n",
    "\n",
    "\n",
    "# LightGBM parameters\n",
    "lgb_param_grid = {\n",
    "                 #'learning_rate': [0.1, 0.05],\n",
    "                 'num_leaves' : [63],\n",
    "                 #'num_leaves' : [12, 15, 18],\n",
    "                 'max_depth'  : [21],\n",
    "                 #'max_depth'  : [6, 9, 15],\n",
    "                 #'min_gain_to_split' : [0, 0.1, 0.2],\n",
    "                 #'feature_fraction' : [0.5, 0.7, 1],\n",
    "                 #'bagging_fraction' : [0.7, 0.9, 1],\n",
    "                 #'min_sum_hessian_in_leaf' : [1, 2, 4],\n",
    "                }\n",
    "\n",
    "callbacks = [early_stopping(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extree_predictions = []\n",
    "extree_scores = []\n",
    "extree_feature_importance = []\n",
    "extree_result = {}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n",
    "\n",
    "    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    ### データセット作成\n",
    "    X_train, X_val = train.iloc[train_idx][FEATURES], train.iloc[val_idx][FEATURES]\n",
    "    y_train, y_val = train[TARGET].iloc[train_idx] , train[TARGET].iloc[val_idx]\n",
    "\n",
    "    ### 学習\n",
    "    lgb_model = LGBMClassifier(**lgb_fixed_params)\n",
    "\n",
    "    # gs = GridSearchCV(model, param_grid=lgb_param_grid, fit_params=lgb_fixed_params, cv=FOLDS, n_jobs=-1, verbose=2)\n",
    "    gs_lgb = GridSearchCV(lgb_model, param_grid=lgb_param_grid, cv=FOLDS, n_jobs=-1, verbose=2)\n",
    "    gs_lgb.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=0, callbacks=callbacks)\n",
    "\n",
    "    #model.fit(X_train, y_train,verbose=0)\n",
    "    #model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=0, callbacks=callbacks)\n",
    "\n",
    "    ### 結果格納\n",
    "    extree_result[f'Fold{fold}_best_estimator'] = gs_lgb.best_estimator_\n",
    "    extree_result[f'Fold{fold}_best_score'] = gs_lgb.best_score_\n",
    "    extree_result[f'Fold{fold}_best_grid_params'] = gs_lgb.best_params_\n",
    "    extree_result[f'Fold{fold}_best_all_params'] = extree_result[f'Fold{fold}_best_estimator'].get_params()\n",
    "    extree_result[f'Fold{fold}_cv_result'] = pd.DataFrame(gs_lgb.cv_results_)\n",
    "\n",
    "    ### Best Score\n",
    "    print(f\"Best Score: {gs_lgb.best_score_}\")\n",
    "    print(f\"Best Param: {gs_lgb.best_params_}\")\n",
    "\n",
    "    ### 推論（validation）\n",
    "    preds_val = gs_lgb.predict(X_val)\n",
    "    acc = accuracy_score(y_val, preds_val)\n",
    "    extree_scores.append(acc)\n",
    "\n",
    "    ### 結果格納\n",
    "    extree_result[f'Fold{fold}_preds_val'] = preds_val\n",
    "    extree_result[f'Fold{fold}_y_val'] = y_val\n",
    "    extree_result[f'Fold{fold}_acc'] = acc\n",
    "\n",
    "    ### feature importance\n",
    "    feat_imp = pd.DataFrame(index=FEATURES, data=extree_result[f'Fold{fold}_best_estimator'].feature_importances_, columns=[f'{fold}_importance'])\n",
    "    extree_feature_importance.append(feat_imp)\n",
    "\n",
    "    ### 推論（test）\n",
    "    test_preds = gs_lgb.predict(test[FEATURES])\n",
    "    extree_predictions.append(test_preds)\n",
    "\n",
    "    ### 結果表示\n",
    "    run_time = time.time() - start_time\n",
    "    print(f\"Fold={fold+1}, Accuracy: {acc:.5f}, Run Time: {run_time:.2f}s\")\n",
    "\n",
    "print(10*\"=\", \"Cross Validation finished.\", 10*\"=\")\n",
    "print(\"Mean Accuracy :\", np.mean(extree_scores))\n",
    "print(extree_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(FOLDS):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    cm = confusion_matrix(lgb_result[f'Fold{fold}_y_val'], lgb_result[f'Fold{fold}_preds_val'])\n",
    "    display(accuracy_score(lgb_result[f'Fold{fold}_y_val'], lgb_result[f'Fold{fold}_preds_val']))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_fis_df = pd.concat(lgb_feature_importance, axis=1).head(15)\n",
    "lgbm_fis_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_submission = submission.copy()\n",
    "lgb_submission[TARGET] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(lgb_predictions),axis = 1)[0]).astype('int'))\n",
    "#lgb_submission[TARGET] = np.squeeze(mode(np.column_stack(lgb_predictions),axis = 1)[0]).astype('int')\n",
    "### 列方向にリストを行列化して、各行の最頻値をとって、１次元の配列は削除して、intにして、数値をラベルに戻している\n",
    "\n",
    "lgb_submission.to_csv(f\"../data/submission/nb{NB}_LGBM.csv\",index=False)\n",
    "lgb_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\"early_stopping_rounds\": 100,\n",
    "              \"eval_set\": [[X_test, y_test]]}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "gs = GridSearchCV(xgb_model,\n",
    "                  params,\n",
    "                  fit_params=fit_params,\n",
    "                  cv=10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "def GridSearchCV_XGB_early_stoppping(param_grid, param_fixed, scorer, cv, X, y):\n",
    "    \"\"\"This function performs grid search for the best set of parameters of XGBoost model with early stopping.\n",
    "\n",
    "    Args:\n",
    "        param_grid (dict): The parameter ranges for which the function searches.\n",
    "        param_fixed (dict): The fitting parameters for XGBoost.\n",
    "        scorer (_PredictScorer): The sklearn's scorer instance.\n",
    "        cv (model_selection._split): The sklearn's split instance.\n",
    "        X (DataFrame): The input data matrix.\n",
    "        y (Series): The ground truth label.\n",
    "\n",
    "    Returns:\n",
    "        dict: The best set of parameters found via grid search.\n",
    "    \"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_numpy()\n",
    "\n",
    "    param_names, param_values = zip(*list(param_grid.items()))\n",
    "\n",
    "    cv_best_iterations = defaultdict(list)\n",
    "    cv_results = defaultdict(list)\n",
    "\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        gscv_x_train, gscv_x_val = X[train_index], X[test_index]\n",
    "        gscv_y_train, gscv_y_val = y[train_index], y[test_index]\n",
    "\n",
    "        param_fixed_cv = deepcopy(param_fixed)\n",
    "        param_fixed_cv['eval_set'] = [(gscv_x_val, gscv_y_val)]\n",
    "\n",
    "        for value_combination in product(*param_values):\n",
    "            param_grid_cv = tuple(zip(param_names, value_combination))\n",
    "            xgboost = XGBRegressor(**dict(param_grid_cv))\n",
    "\n",
    "            xgboost.fit(gscv_x_train, gscv_y_train, **param_fixed_cv)\n",
    "            if 'early_stopping_rounds' not in param_fixed_cv:\n",
    "                best_iteration = xgboost.get_num_boosting_rounds()\n",
    "            else:\n",
    "                best_iteration = xgboost.best_iteration\n",
    "            cv_best_iterations[param_grid_cv].append(best_iteration)\n",
    "\n",
    "            score = scorer(xgboost, gscv_x_val, gscv_y_val)\n",
    "            cv_results[param_grid_cv].append(score)\n",
    "\n",
    "    best_params_xgb, score_list = max(cv_results.items(), key=lambda x: np.array(x[1]).mean())\n",
    "\n",
    "    # Note that our XGBoost model may stop early,\n",
    "    # so we calculate the mean of the actual number of estimators in each fold,\n",
    "    # in place of the originally planned n_estimators after finishing cross validation.\n",
    "    n_estimators = int(round(np.array(cv_best_iterations[best_params_xgb]).mean()))\n",
    "\n",
    "    best_params_xgb = dict(best_params_xgb)\n",
    "    best_params_xgb['n_estimators'] = n_estimators\n",
    "\n",
    "    print (\"Best score: {:.3f}\".format(np.array(score_list).mean()))\n",
    "    print (\"Best Parameters: {}\".format(best_params_xgb))\n",
    "\n",
    "    return best_params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc8a78a13283e3ba74119858067a74c2c7a55702e09c935fdd8fe4b244251524"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
